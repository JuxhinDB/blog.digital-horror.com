
<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN" "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
    <head>
        <title>Digital Horror</title>
        <meta name="description" content="Contrasting Python and Rust programming languages through the trivial application of the Kohonen-Grossberg Neural Network model.">
        <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<!-- Load light and dark themes for syntax highlighting -->
<link id="prism-light-theme" href="/themes/prism-theme-github-light.css" rel="stylesheet" />
<link id="prism-dark-theme" href="/themes/prism-theme-github-dark.css" media="none" rel="stylesheet" />
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.27.0/prism.min.js"></script>

<!-- Load light and dark themes for overall layout -->
<link class="main-stylesheet" id="light-mode" rel="stylesheet" href="/css/styles.css">
<link class="main-stylesheet" id="dark-mode" rel="stylesheet" media="none" href="/css/styles-dark.css" />

<!-- Add webfont support -->
<link rel="stylesheet" href="/fonts/icons.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@mdi/font@latest/css/materialdesignicons.min.css">

<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=Lato&family=Merriweather&display=swap" rel="stylesheet">
<link href="https://fonts.googleapis.com/css2?family=Lato:wght@400;700&display=swap" rel="stylesheet">

<script>
    function waitForElem(selector) {
        return new Promise(resolve => {
            if (document.querySelector(selector)) {
                console.log('element already exists');
                return resolve(document.querySelector(selector));
            }
    
            const observer = new MutationObserver(mutations => {
                if (document.querySelector(selector)) {
                    console.log('found element ' + selector);
                    resolve(document.querySelector(selector));
                    observer.disconnect();
                }
            });
    
            observer.observe(document.body, {
                  childList: true
                , subtree: true
                , attributes: false
                , characterData: false
            });
        });
    }
</script>

    </head>
    <body>
    <div class="container content-container">
        <header>
   <div class="header-content">
       <div class="header-center">
           <a href="/">Digital Horror</a>
       </div>
       <div class="header-right">
           <span id="dark-mode-toggle" class="mdi mdi-theme-light-dark"></span>
       </div>
   </div>
</header>



        <main>
            <article class="post">
            <h2 class="post-title">Rust & Pythonâ€”A Gentle Comparison using Simple Neural Networks</h2>
            <p class="post-date">12/23/2018</p>
                <div class = "post-content"> 
                <h4><a href="#disclaimer" aria-hidden="true" class="anchor" id="header-disclaimer"></a>Disclaimer</h4>
<blockquote>
<p>I am by no means proficient in Rust as you very well will see. As a  result, these results should be taken with a pinch of salt. Any  improvements are most welcome! There are some great discussions over at the <a href="https://www.reddit.com/r/rust/comments/a8wfpf/rust_pythona_gentle_comparison_using_simple/">/r/rust</a> subreddit for more information about code optimisation that I highly recommend reading.</p>
</blockquote>
<h2><a href="#introduction" aria-hidden="true" class="anchor" id="header-introduction"></a>Introduction</h2>
<p>I recently had a task to implement a very simple <a href="https://en.wikipedia.org/wiki/Self-organizing_map">Kohonen-Grossberg Neural Network</a> which was particularly fun due to being relatively simple to implement.</p>
<p>My initial implementation was in Python with less than 60 lines of  code. I wrapped a CLI around it and sat at around 90 lines of code.</p>
<p>After some thought, I figured that this would be a great  learning experience for Rust (and it was) and would give me the  opportunity to compare the two languages from multiple perspectives.</p>
<h3><a href="#implementation" aria-hidden="true" class="anchor" id="header-implementation"></a>Implementation</h3>
<p>The following are the two implementations of KNN in Python and Rust. Keep in mind that this was originally written in Python and then ported to Rust.</p>
<h4><a href="#python-implementation" aria-hidden="true" class="anchor" id="header-python-implementation"></a>Python Implementation</h4>
<p>The following is the Python implementation which you can find <a href="https://gist.github.com/JuxhinDB/47f90374af3a6328f5090401da09128b">here</a>.</p>
<pre><code class="language-python">__author__ = 'Juxhin Dyrmishi Brigjaj'

import sys
import math
import random
import argparse


def parse_args():
    parser = argparse.ArgumentParser(description='A naive Kohonen-Grossberg Counterpropogation Network in Python')
    parser.add_argument('-l', '--learning-rate', metavar='R', type=float, required=True,
                        help='Float indicating the learning rate (step) the network should use')
    parser.add_argument('-f', '--csv-file', type=str, required=True,
                        help='Path to CSV file containing dataset')
    parser.add_argument('-e', '--epoch', type=int, help=&quot;Number of epochs to complete&quot;, required=True, default=1000)
    parser.add_argument('-n', '--neurons', type=int, help=&quot;Number of neurons (units) to generate&quot;, required=True, default=3)
    return parser.parse_args()


def normalise(rows: list=()) -&gt; list:

    _result = []

    for row in rows:
        _vector_length = math.sqrt(sum([x**2 for x in row]))
        _result.append([round(x / _vector_length, 4) for x in row])

    return _result


def generate_random_units(col_len: int, row_len: int) -&gt; list:
    _result = []
    for _ in range(0, row_len):

        _result.append([round(random.uniform(0.0, 1.0), 4) for _ in range(0, col_len)])
    return _result


def calculate_nets(row, units):
    _nets = []
    for unit in units:
        _net = 0.0
        for i, _ in enumerate(unit):
            _net += round(row[i] * unit[i], 4)
        _nets.append(round(_net, 4))
    return _nets


def update_units(learning_rate: float, nets: list, row: list, units: list) -&gt; bool:
    _i = nets.index(max(nets))

    for _j, column in enumerate(row):
        units[_i][_j] = round(units[_i][_j] + learning_rate * (column - units[_i][_j]), 4)


def main():
    args = parse_args()

    learning_rate = args.learning_rate
    unnormalised_dataset = []

    try:
        with open(args.csv_file, 'r') as csv_file:
            for line in csv_file:
                unnormalised_dataset.append([float(x) for x in line.split(',')])
    except TypeError as e:
        print(&quot;[!] FATAL: Dataset is malformed. Unable to parse values as floats.\n{}&quot;.format(str(e)))

    print(&quot;[+] Normalising dataset&quot;)

    rows = normalise(unnormalised_dataset)

    for row in rows:
        print('\t'.join([str(x) for x in row]))

    # Used to determine the number of columns in generate_random_units call
    # assuming that the dataset is consistent in width

    __unit_length = len(unnormalised_dataset[0])
    random_units = generate_random_units(__unit_length, args.neurons)

    print(&quot;\n[+] Starting Weights:&quot;)
    for unit in random_units:
        print(','.join([str(x) for x in unit]))
    print()


    for i in range(1, args.epoch + 1):

        if i % 100 == 0:
            print(&quot;[+] Running Epoch #{}&quot;.format(str(i)))
        for row in rows:
            nets = calculate_nets(row, random_units)
            update_units(learning_rate, nets, row, random_units)

    print(&quot;\n[+] Final Weights:&quot;)
    for unit in random_units:
        print(','.join([str(x) for x in unit]))

if __name__ == '__main__':
    main()
</code></pre>
<h4><a href="#rust-implementation" aria-hidden="true" class="anchor" id="header-rust-implementation"></a>Rust Implementation</h4>
<p>You can find the Rust implementation <a href="https://github.com/JuxhinDB/rust-snippets/blob/master/KohonenGrossberg-NN/src/main.rs">here</a>.</p>
<pre><code class="language-rust">#[macro_use]
extern crate clap;

use std::fs::File;

use clap::App;
use rand::distributions::{Distribution, Standard};


fn normalise(rows: &amp;mut Vec&lt;Vec&lt;f32&gt;&gt;) {
    for row in rows.iter_mut() {
        let vector_length = row.into_iter().map(|x| x.powf(2.0)).fold(0.0, |a, b| a + b).sqrt();
        *row = row.into_iter().map(|x| *x / vector_length).collect();
    }
}

fn generate_random_units(col_len: &amp;usize, row_len: &amp;usize) -&gt; Vec&lt;Vec&lt;f32&gt;&gt; {
    let mut rng = rand::thread_rng();

    std::iter::repeat_with(|| 
        Standard.sample_iter(&amp;mut rng).take(*col_len).collect())
        .take(*row_len)
        .collect()
}

fn calculate_nets(row: &amp;Vec&lt;f32&gt;, units: &amp;Vec&lt;Vec&lt;f32&gt;&gt;) -&gt; Vec&lt;f32&gt; {

    let mut nets: Vec&lt;f32&gt; = Vec::with_capacity(units.len());

    for unit in units.iter() {
        let mut _net = 0.0;

        for (i, _) in unit.iter().enumerate() {
            unsafe {
                _net += row.get_unchecked(i as usize) * unit.get_unchecked(i as usize);            
            }
        }

        nets.push(_net);
    }

    nets
}

fn update_units(learning_rate: f32, nets: &amp;Vec&lt;f32&gt;, row: &amp;Vec&lt;f32&gt;, units: &amp;mut Vec&lt;Vec&lt;f32&gt;&gt;) {

    // Sub-optimal...
    let mut iter = nets.iter().enumerate();
    let init = iter.next().unwrap();

    // https://stackoverflow.com/questions/53903318/rust-idiomatic-way-to-get-index-of-max-float-value-in-a-vec?noredirect=1#comment94651877_53903318
    let _i = iter.try_fold(init, |acc, x| {

        if let Some(_i) = x.1.partial_cmp(acc.1) {
            Some(if let std::cmp::Ordering::Greater = _i {
                x
            } else {
                acc
            })
        } else {
            None
        }
    }).unwrap().0;

    row.iter().enumerate().for_each(|(_j, column)| {
        units[_i][_j] += learning_rate * (column - units[_i][_j]);
    });
}

fn main() {
    let yaml = load_yaml!(&quot;clap-cli.yml&quot;);
    let matches = App::from_yaml(yaml).get_matches();

    let learning_rate = value_t!(matches, &quot;LearningRate&quot;, f32).unwrap_or_else(|e| e.exit());
    let epoch = value_t!(matches, &quot;Epoch&quot;, usize).unwrap_or_else(|e| e.exit());
    let neurons = value_t!(matches, &quot;Neurons&quot;, usize).unwrap_or_else(|e| e.exit());

    let mut dataset: Vec&lt;Vec&lt;f32&gt;&gt; = Vec::new();

    let file = File::open(matches.value_of(&quot;CSVFile&quot;).unwrap()).unwrap();
    let mut reader = csv::Reader::from_reader(file);

    for result in reader.records() {

        dataset.push(result.unwrap().iter().map(|x| {
            x.parse::&lt;f32&gt;().unwrap()
        }).collect());
    }

    println!(&quot;\n[+] Normalising dataset&quot;);
    normalise(&amp;mut dataset);

    for row in &amp;dataset {
        println!(&quot;{:?}&quot;, &amp;row);
    }

    let __unit_length = &amp;dataset[0].len();
    let mut units = generate_random_units(__unit_length, &amp;neurons);
    println!(&quot;\nStarting Weights:&quot;);
    units.iter().for_each(|unit| {
        println!(&quot;{:?}&quot;, unit)
    });

    println!();

    for i in 1..epoch+1 {
        if i % 100 == 0 {
            println!(&quot;[+] Running Epoch #{:?}&quot;, &amp;epoch);
        }


        for row in &amp;dataset {
            let nets = calculate_nets(&amp;row, &amp;units);
            update_units(learning_rate, &amp;nets, &amp;row, &amp;mut units);
        }
    }

    println!(&quot;\n[+] Final Weights:&quot;);
    units.iter().for_each(|unit| {
        println!(&quot;{:?}&quot;, unit)
    });
}
</code></pre>
<p>If you want to test this with the sample dataset I used, you can find it <a href="https://web.archive.org/web/20190509223238/https://gist.github.com/JuxhinDB/2003e14bd6521afcc285077036f938e7">here</a>. Ofcourse, feel free to test this with larger datasets, both in dimensions and count.</p>
<h2><a href="#usage" aria-hidden="true" class="anchor" id="header-usage"></a>Usage</h2>
<p>The CLI for both implementations are essentially the same (minus defaults not being handled in Rust via Clap).</p>
<pre><code class="language-none">KohonenGrossberg-NN.exe --help
KohonenGrossberg-NN 1.0
Juxhin D. Brigjaj &lt;juxhinbox at gmail.com&gt;
A naive Kohonen-Grossberg Counterpropogation Network in Rust

USAGE:
    KohonenGrossberg-NN.exe --csv-file &lt;CSVFile&gt; --epoch &lt;Epoch&gt; --learning-rate &lt;R&gt; --neurons &lt;Neurons&gt;

FLAGS:
    -h, --help       Prints help information
    -V, --version    Prints version information

OPTIONS:
    -f, --csv-file &lt;CSVFile&gt;    Path to CSV file containing dataset
    -e, --epoch &lt;Epoch&gt;         Number of epochs to complete
    -l, --learning-rate &lt;R&gt;     Float indicating the learning rate (step) the network should use (i.e. 0.1)
    -n, --neurons &lt;Neurons&gt;     Number of neurons (units) to generate
</code></pre>
<p>Running it against the previous dataset with the following parameters.</p>
<ul>
<li>Learning Rate: 0.1</li>
<li>Epoch(s): 100</li>
<li>Neurons: 3</li>
</ul>
<pre><code class="language-none">KohonenGrossberg-NN.exe -f &quot;\path\to\2d-unnormalised-dataset.csv&quot; -e 100 -l 0.1 -n 3

[+] Normalising dataset
[-0.85355574, 0.5210016]
... TRUNCATED ...
[0.99772507, -0.06741386]

Starting Weights:
[0.8944668, 0.8694155]
[0.0746305, 0.84058756]
[0.34859443, 0.71816105]

[+] Running Epoch #100

[+] Final Weights:
[0.95343673, -0.24061918]
[-0.75190365, 0.6541567]
[0.43543196, 0.8938945]
</code></pre>
<p>If we take each distinct section and plot it using <a href="https://www.desmos.com/calculator">desmos</a> we can observe the result.</p>
<h5><a href="#legend" aria-hidden="true" class="anchor" id="header-legend"></a>Legend</h5>
<ul>
<li>Green circle: normalised dataset</li>
<li>Purple circle: Initial random weights</li>
<li>Black cross: Weights localised to each cluster</li>
</ul>
<blockquote>
<p><em>Unfortunately these images have been lost in time. If demanded, I can attempt to recreate them</em>.</p>
</blockquote>
<h2><a href="#performance" aria-hidden="true" class="anchor" id="header-performance"></a>Performance</h2>
<p>Starting off with the Python implementation on a small dataset with 5000 data entries.</p>
<pre><code class="language-none">Measure-Command { python .\KohonenGrossberg-NN.py -f &quot;.\2d-unnormalised-dataset.csv&quot; -e 100 -l 0.1 -n 3 }

TotalSeconds      : 4.2432031
TotalMilliseconds : 4243.2031
</code></pre>
<p>Compared with the Rust implementation on the same dataset.</p>
<pre><code class="language-none">Measure-Command { .\KohonenGrossberg-NN.exe -f &quot;.\2d-unnormalised-dataset.csv&quot; -e 100 -n 3 -l 0.1 }

TotalSeconds      : 0.0667547
TotalMilliseconds : 66.7547
</code></pre>
<h2><a href="#results" aria-hidden="true" class="anchor" id="header-results"></a>Results</h2>
<p>I kept increasing the dataset in checkpoints increasing over time up to 150k lines.</p>
<pre><code class="language-none">Python      Rust        Lines
72.114      13.1077     24
117.7726    18.2308     48
141.9611    18.8265     100
476.7803    21.0633     500
884.6529    23.1228     1000
4243.2031   66.7547     4999
124274.4748 1751.4639   150000
</code></pre>
<p>Whilst I did expect Rust to be faster, the margin seemed excessive. Profiling the Python implementation, I noticed the following.</p>
<pre><code class="language-none">Name                                # Calls Time(ms) 
&lt;built-in method builtins.round&gt;    5508904	2701
calculate_nets	                    499900	3588
update_units	                      499900	1273
main	                              1	    5098
</code></pre>
<p>Looks like the built-in <code>round()</code> function took 53% of the execution time! Removing all floating-point <code>round()</code> calls alters the result by a noticeable degree.</p>
<pre><code class="language-none">Python      Rust        Lines
59.4613     13.1077     24
64.5703     18.2308     48
79.1932     18.8265     100
174.9629    21.0633     500
304.2106    23.1228     1000
1321.0426   66.7547     4999
39051.7759  1751.4639   150000
</code></pre>
<p>Overall we are looking at a ~22x advantage that Rust has over Python. This seemed more reasonble compared to the previous result.</p>
<h2><a href="#thoughts" aria-hidden="true" class="anchor" id="header-thoughts"></a>Thoughts</h2>
<p>The idea behind this post was not to point out how fast Rust is compared to Python. Rather, how fast it is against the ease-of-use that Python provides.</p>
<p>There are many simple scenarios that Python handles beautifully if accurate assumptions are made. For example, getting the index of the largest <code>f32</code> in a list.</p>
<p>In Python we can simply write the following.</p>
<pre><code class="language-python">_i = nets.index(max(nets))
</code></pre>
<p>The same can't be said for Rust (see <a href="https://web.archive.org/web/20190509223238/https://stackoverflow.com/questions/53903318/rust-idiomatic-way-to-get-index-of-max-float-value-in-a-vec?noredirect=1#comment94651877_53903318">this</a> StackOverflow question I posted).</p>
<pre><code class="language-rust">let mut iter = nets.iter().enumerate();
let init = iter.next().unwrap();

let _i = iter.try_fold(init, |acc, x| {
    if let Some(_i) = x.1.partial_cmp(acc.1) {
        Some(if let std::cmp::Ordering::Greater = _i {
            x
        } else {
            acc
        })
    } else {
        None
    }
}).unwrap().0;
</code></pre>
<p>Another example is generating the initial random weights. Using uniform distribution in python is beautiful.</p>
<pre><code class="language-python">for _ in range(0, row_len):
      _result.append([random.uniform(0.0, 1.0) for _ in range(0, col_len)])
</code></pre>
<p>Whereas with Rust it's far more obscure and hard to understand, at the very least to an untrained eye (in functional programming).</p>
<blockquote>
<p><strong>Note</strong> â€” looking back at this blog post I would definitely say that the second example is a lot more intuitive to read!</p>
</blockquote>
<pre><code class="language-rust">let mut rng = rand::thread_rng();

std::iter::repeat_with(|| 
    Standard.sample_iter(&amp;mut rng).take(*col_len).collect())
    .take(*row_len)
    .collect()
</code></pre>
<h2><a href="#conclusion" aria-hidden="true" class="anchor" id="header-conclusion"></a>Conclusion</h2>
<p>Despite the odd quirks and syntax, I'm in love with Rust, its performance, compiler and community. That said, I still use Python every day for most operations and feel that I can use Rust and Python hand-in-hand to complement eachother when needed.I can also see myself creating effective Proof-of-Concepts in Python then porting them over to Rust</p>

                </div>
            </article>
        </main>
    </div>

    <footer>
   <div class="footer-content">
       <div class="footer-center">
           &copy; 2023 Digital Horror. All rights reserved.
       </div>
       <div class="footer-right">
           <a href="https://linkedin.com/in/juxhin-db" target="_blank" rel="noopener noreferrer" class="social-icon">
               <span class="mdi mdi-linkedin"></span>
           </a>
           <a href="https://twitter.com/juxhindb" target="_blank" rel="noopener noreferrer" class="social-icon">
               <span class="mdi mdi-twitter"></span>
           </a>
           <a href="https://github.com/juxhindb" target="_blank" rel="noopener noreferrer" class="social-icon">
               <span class="mdi mdi-github"></span>
           </a>
       </div>
   </div>
</footer>



    <script src="/js/script.js" defer></script>
    <script src="/js/prism.js" defer></script>

    </body>
</html>
        